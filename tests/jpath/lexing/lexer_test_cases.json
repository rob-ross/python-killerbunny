{
    "description": "Lexer tests of example paths in RFC 9535 tables 2-18. This file is autogenerated, do not edit.",
    "tests": [
        {
            "test_name": "table_02-$.store.book[*].author",
            "json_path": "$.store.book[*].author",
            "lexer_tokens": "DOLLAR, DOT, ID:store, DOT, ID:book, LBRACKET, STAR, RBRACKET, DOT, ID:author, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..author",
            "json_path": "$..author",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:author, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$.store.*",
            "json_path": "$.store.*",
            "lexer_tokens": "DOLLAR, DOT, ID:store, DOT, STAR, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$.store..price",
            "json_path": "$.store..price",
            "lexer_tokens": "DOLLAR, DOT, ID:store, DOUBLE_DOT, ID:price, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[2]",
            "json_path": "$..book[2]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, INT:2, RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[2].author",
            "json_path": "$..book[2].author",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, INT:2, RBRACKET, DOT, ID:author, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[2].publisher",
            "json_path": "$..book[2].publisher",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, INT:2, RBRACKET, DOT, ID:publisher, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[-1]",
            "json_path": "$..book[-1]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, INT:-1, RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[0,1]",
            "json_path": "$..book[0,1]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, INT:0, COMMA, INT:1, RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[:2]",
            "json_path": "$..book[:2]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, SLICE[:2], RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[?@.isbn]",
            "json_path": "$..book[?@.isbn]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, QMARK, AT, DOT, ID:isbn, RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..book[?@.price<10]",
            "json_path": "$..book[?@.price<10]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:book, LBRACKET, QMARK, AT, DOT, ID:price, LT, INT:10, RBRACKET, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_02-$..*",
            "json_path": "$..*",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, STAR, EOF",
            "source_file_name": "table_02",
            "is_invalid": false
        },
        {
            "test_name": "table_03-$",
            "json_path": "$",
            "lexer_tokens": "DOLLAR, EOF",
            "source_file_name": "table_03",
            "is_invalid": false
        },
        {
            "test_name": "table_05-$.o['j j']",
            "json_path": "$.o['j j']",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STRING:'j j', RBRACKET, EOF",
            "source_file_name": "table_05",
            "is_invalid": false
        },
        {
            "test_name": "table_05-$.o['j j']['k.k']",
            "json_path": "$.o['j j']['k.k']",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STRING:'j j', RBRACKET, LBRACKET, STRING:'k.k', RBRACKET, EOF",
            "source_file_name": "table_05",
            "is_invalid": false
        },
        {
            "test_name": "table_05-$.o[\"j j\"][\"k.k\"]",
            "json_path": "$.o[\"j j\"][\"k.k\"]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STRING:\"j j\", RBRACKET, LBRACKET, STRING:\"k.k\", RBRACKET, EOF",
            "source_file_name": "table_05",
            "is_invalid": false
        },
        {
            "test_name": "table_05-$['o']['j j']['k.k']",
            "json_path": "$['o']['j j']['k.k']",
            "lexer_tokens": "DOLLAR, LBRACKET, STRING:'o', RBRACKET, LBRACKET, STRING:'j j', RBRACKET, LBRACKET, STRING:'k.k', RBRACKET, EOF",
            "source_file_name": "table_05",
            "is_invalid": false
        },
        {
            "test_name": "table_05-$[\"'\"][\"@\"]",
            "json_path": "$[\"'\"][\"@\"]",
            "lexer_tokens": "DOLLAR, LBRACKET, STRING:\"'\", RBRACKET, LBRACKET, STRING:\"@\", RBRACKET, EOF",
            "source_file_name": "table_05",
            "is_invalid": false
        },
        {
            "test_name": "table_06-$[*]",
            "json_path": "$[*]",
            "lexer_tokens": "DOLLAR, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_06",
            "is_invalid": false
        },
        {
            "test_name": "table_06-$.o[*]",
            "json_path": "$.o[*]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_06",
            "is_invalid": false
        },
        {
            "test_name": "table_06-$.o[*]",
            "json_path": "$.o[*]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_06",
            "is_invalid": false
        },
        {
            "test_name": "table_06-$.o[*, *]",
            "json_path": "$.o[*, *]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, STAR, COMMA, STAR, RBRACKET, EOF",
            "source_file_name": "table_06",
            "is_invalid": false
        },
        {
            "test_name": "table_06-$.a[*]",
            "json_path": "$.a[*]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_06",
            "is_invalid": false
        },
        {
            "test_name": "table_07-$[1]",
            "json_path": "$[1]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:1, RBRACKET, EOF",
            "source_file_name": "table_07",
            "is_invalid": false
        },
        {
            "test_name": "table_07-$[-2]",
            "json_path": "$[-2]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:-2, RBRACKET, EOF",
            "source_file_name": "table_07",
            "is_invalid": false
        },
        {
            "test_name": "table_09-$[1:3]",
            "json_path": "$[1:3]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[1:3], RBRACKET, EOF",
            "source_file_name": "table_09",
            "is_invalid": false
        },
        {
            "test_name": "table_09-$[5:]",
            "json_path": "$[5:]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[5:], RBRACKET, EOF",
            "source_file_name": "table_09",
            "is_invalid": false
        },
        {
            "test_name": "table_09-$[1:5:2]",
            "json_path": "$[1:5:2]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[1:5:2], RBRACKET, EOF",
            "source_file_name": "table_09",
            "is_invalid": false
        },
        {
            "test_name": "table_09-$[5:1:-2]",
            "json_path": "$[5:1:-2]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[5:1:-2], RBRACKET, EOF",
            "source_file_name": "table_09",
            "is_invalid": false
        },
        {
            "test_name": "table_09-$[::-1]",
            "json_path": "$[::-1]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[::-1], RBRACKET, EOF",
            "source_file_name": "table_09",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.absent1 == $.absent2",
            "json_path": "$.absent1 == $.absent2",
            "lexer_tokens": "DOLLAR, DOT, ID:absent1, EQUAL, DOLLAR, DOT, ID:absent2, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.absent1 <= $.absent2",
            "json_path": "$.absent1 <= $.absent2",
            "lexer_tokens": "DOLLAR, DOT, ID:absent1, LTE, DOLLAR, DOT, ID:absent2, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.absent == 'g'",
            "json_path": "$.absent == 'g'",
            "lexer_tokens": "DOLLAR, DOT, ID:absent, EQUAL, STRING:'g', EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.absent1 != $.absent2",
            "json_path": "$.absent1 != $.absent2",
            "lexer_tokens": "DOLLAR, DOT, ID:absent1, NOT_EQUAL, DOLLAR, DOT, ID:absent2, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.absent != 'g'",
            "json_path": "$.absent != 'g'",
            "lexer_tokens": "DOLLAR, DOT, ID:absent, NOT_EQUAL, STRING:'g', EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1 <= 2",
            "json_path": "1 <= 2",
            "lexer_tokens": "INT:1, LTE, INT:2, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1> 2",
            "json_path": "1> 2",
            "lexer_tokens": "INT:1, GT, INT:2, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-13 == '13'",
            "json_path": "13 == '13'",
            "lexer_tokens": "INT:13, EQUAL, STRING:'13', EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-'a' <= 'b'",
            "json_path": "'a' <= 'b'",
            "lexer_tokens": "STRING:'a', LTE, STRING:'b', EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-'a' > 'b'",
            "json_path": "'a' > 'b'",
            "lexer_tokens": "STRING:'a', GT, STRING:'b', EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj == $.arr",
            "json_path": "$.obj == $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, EQUAL, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj != $.arr",
            "json_path": "$.obj != $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, NOT_EQUAL, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj == $.obj",
            "json_path": "$.obj == $.obj",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, EQUAL, DOLLAR, DOT, ID:obj, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj != $.obj",
            "json_path": "$.obj != $.obj",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, NOT_EQUAL, DOLLAR, DOT, ID:obj, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.arr == $.arr",
            "json_path": "$.arr == $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:arr, EQUAL, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.arr != $.arr",
            "json_path": "$.arr != $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:arr, NOT_EQUAL, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj == 17",
            "json_path": "$.obj == 17",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, EQUAL, INT:17, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj != 17",
            "json_path": "$.obj != 17",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, NOT_EQUAL, INT:17, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj <= $.arr",
            "json_path": "$.obj <= $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, LTE, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj < $.arr",
            "json_path": "$.obj < $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, LT, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.obj <= $.obj",
            "json_path": "$.obj <= $.obj",
            "lexer_tokens": "DOLLAR, DOT, ID:obj, LTE, DOLLAR, DOT, ID:obj, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-$.arr <= $.arr",
            "json_path": "$.arr <= $.arr",
            "lexer_tokens": "DOLLAR, DOT, ID:arr, LTE, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1 <= $.arr",
            "json_path": "1 <= $.arr",
            "lexer_tokens": "INT:1, LTE, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1 >= $.arr",
            "json_path": "1 >= $.arr",
            "lexer_tokens": "INT:1, GTE, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1 > $.arr",
            "json_path": "1 > $.arr",
            "lexer_tokens": "INT:1, GT, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-1 < $.arr",
            "json_path": "1 < $.arr",
            "lexer_tokens": "INT:1, LT, DOLLAR, DOT, ID:arr, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-true <= true",
            "json_path": "true <= true",
            "lexer_tokens": "KEYWORD:true, LTE, KEYWORD:true, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_11-true > true",
            "json_path": "true > true",
            "lexer_tokens": "KEYWORD:true, GT, KEYWORD:true, EOF",
            "source_file_name": "table_11",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@.b == 'kilo']",
            "json_path": "$.a[?@.b == 'kilo']",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, DOT, ID:b, EQUAL, STRING:'kilo', RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?(@.b == 'kilo')]",
            "json_path": "$.a[?(@.b == 'kilo')]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, LPAREN, AT, DOT, ID:b, EQUAL, STRING:'kilo', RPAREN, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@>3.5]",
            "json_path": "$.a[?@>3.5]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, GT, FLOAT:3.5, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@.b]",
            "json_path": "$.a[?@.b]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, DOT, ID:b, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$[?@.*]",
            "json_path": "$[?@.*]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, AT, DOT, STAR, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$[?@[?@.b]]",
            "json_path": "$[?@[?@.b]]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, AT, LBRACKET, QMARK, AT, DOT, ID:b, RBRACKET, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.o[?@<3, ?@<3]",
            "json_path": "$.o[?@<3, ?@<3]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, QMARK, AT, LT, INT:3, COMMA, QMARK, AT, LT, INT:3, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@<2 || @.b == \"k\"]",
            "json_path": "$.a[?@<2 || @.b == \"k\"]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, LT, INT:2, OR, AT, DOT, ID:b, EQUAL, STRING:\"k\", RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?match(@.b, \"[jk]\")]",
            "json_path": "$.a[?match(@.b, \"[jk]\")]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, ID:match, LPAREN, AT, DOT, ID:b, COMMA, STRING:\"[jk]\", RPAREN, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?search(@.b, \"[jk]\")]",
            "json_path": "$.a[?search(@.b, \"[jk]\")]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, ID:search, LPAREN, AT, DOT, ID:b, COMMA, STRING:\"[jk]\", RPAREN, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.o[?@>1 && @<4]",
            "json_path": "$.o[?@>1 && @<4]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, QMARK, AT, GT, INT:1, AND, AT, LT, INT:4, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.o[?@>1 && @<4]",
            "json_path": "$.o[?@>1 && @<4]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, QMARK, AT, GT, INT:1, AND, AT, LT, INT:4, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.o[?@.u ||  @.x]",
            "json_path": "$.o[?@.u ||  @.x]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, LBRACKET, QMARK, AT, DOT, ID:u, OR, AT, DOT, ID:x, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@.b == $.x]",
            "json_path": "$.a[?@.b == $.x]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, DOT, ID:b, EQUAL, DOLLAR, DOT, ID:x, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_12-$.a[?@ == @]",
            "json_path": "$.a[?@ == @]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, QMARK, AT, EQUAL, AT, RBRACKET, EOF",
            "source_file_name": "table_12",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?length(@) < 3]",
            "json_path": "$[?length(@) < 3]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:length, LPAREN, AT, RPAREN, LT, INT:3, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?length(@.*) < 3]",
            "json_path": "$[?length(@.*) < 3]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:length, LPAREN, AT, DOT, STAR, RPAREN, LT, INT:3, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?count(@.*) == 1]",
            "json_path": "$[?count(@.*) == 1]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:count, LPAREN, AT, DOT, STAR, RPAREN, EQUAL, INT:1, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?count(1) == 1]",
            "json_path": "$[?count(1) == 1]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:count, LPAREN, INT:1, RPAREN, EQUAL, INT:1, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?count(foo(@.*)) == 1]",
            "json_path": "$[?count(foo(@.*)) == 1]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:count, LPAREN, ID:foo, LPAREN, AT, DOT, STAR, RPAREN, RPAREN, EQUAL, INT:1, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?match(@.timezone, 'Europe/.*')]",
            "json_path": "$[?match(@.timezone, 'Europe/.*')]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:match, LPAREN, AT, DOT, ID:timezone, COMMA, STRING:'Europe/.*', RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?match(@.timezone,'Europe/.*') == true]",
            "json_path": "$[?match(@.timezone,'Europe/.*') == true]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:match, LPAREN, AT, DOT, ID:timezone, COMMA, STRING:'Europe/.*', RPAREN, EQUAL, KEYWORD:true, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?value(@..color) == \"red\"]",
            "json_path": "$[?value(@..color) == \"red\"]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:value, LPAREN, AT, DOUBLE_DOT, ID:color, RPAREN, EQUAL, STRING:\"red\", RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?value(@..color)]",
            "json_path": "$[?value(@..color)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:value, LPAREN, AT, DOUBLE_DOT, ID:color, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?bar(@.a)]",
            "json_path": "$[?bar(@.a)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:bar, LPAREN, AT, DOT, ID:a, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?bnl(@.*)]",
            "json_path": "$[?bnl(@.*)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:bnl, LPAREN, AT, DOT, STAR, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?blt(1==1)]",
            "json_path": "$[?blt(1==1)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:blt, LPAREN, INT:1, EQUAL, INT:1, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?blt(1)]",
            "json_path": "$[?blt(1)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:blt, LPAREN, INT:1, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_14-$[?bal(1)]",
            "json_path": "$[?bal(1)]",
            "lexer_tokens": "DOLLAR, LBRACKET, QMARK, ID:bal, LPAREN, INT:1, RPAREN, RBRACKET, EOF",
            "source_file_name": "table_14",
            "is_invalid": false
        },
        {
            "test_name": "table_15-$[0, 3]",
            "json_path": "$[0, 3]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:0, COMMA, INT:3, RBRACKET, EOF",
            "source_file_name": "table_15",
            "is_invalid": false
        },
        {
            "test_name": "table_15-$[0:2, 5]",
            "json_path": "$[0:2, 5]",
            "lexer_tokens": "DOLLAR, LBRACKET, SLICE[0:2], COMMA, INT:5, RBRACKET, EOF",
            "source_file_name": "table_15",
            "is_invalid": false
        },
        {
            "test_name": "table_15-$[0, 0]",
            "json_path": "$[0, 0]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:0, COMMA, INT:0, RBRACKET, EOF",
            "source_file_name": "table_15",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..j",
            "json_path": "$..j",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:j, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..j",
            "json_path": "$..j",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:j, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..[0]",
            "json_path": "$..[0]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, LBRACKET, INT:0, RBRACKET, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..[*]",
            "json_path": "$..[*]",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..*",
            "json_path": "$..*",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, STAR, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$..o",
            "json_path": "$..o",
            "lexer_tokens": "DOLLAR, DOUBLE_DOT, ID:o, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$.o..[*, *]",
            "json_path": "$.o..[*, *]",
            "lexer_tokens": "DOLLAR, DOT, ID:o, DOUBLE_DOT, LBRACKET, STAR, COMMA, STAR, RBRACKET, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_16-$.a..[0, 1]",
            "json_path": "$.a..[0, 1]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, DOUBLE_DOT, LBRACKET, INT:0, COMMA, INT:1, RBRACKET, EOF",
            "source_file_name": "table_16",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.a",
            "json_path": "$.a",
            "lexer_tokens": "DOLLAR, DOT, ID:a, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.a[0]",
            "json_path": "$.a[0]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, LBRACKET, INT:0, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.a.d",
            "json_path": "$.a.d",
            "lexer_tokens": "DOLLAR, DOT, ID:a, DOT, ID:d, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.b[0]",
            "json_path": "$.b[0]",
            "lexer_tokens": "DOLLAR, DOT, ID:b, LBRACKET, INT:0, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.b[*]",
            "json_path": "$.b[*]",
            "lexer_tokens": "DOLLAR, DOT, ID:b, LBRACKET, STAR, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.b[?@]",
            "json_path": "$.b[?@]",
            "lexer_tokens": "DOLLAR, DOT, ID:b, LBRACKET, QMARK, AT, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.b[?@==null]",
            "json_path": "$.b[?@==null]",
            "lexer_tokens": "DOLLAR, DOT, ID:b, LBRACKET, QMARK, AT, EQUAL, KEYWORD:null, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.c[?@.d==null]",
            "json_path": "$.c[?@.d==null]",
            "lexer_tokens": "DOLLAR, DOT, ID:c, LBRACKET, QMARK, AT, DOT, ID:d, EQUAL, KEYWORD:null, RBRACKET, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_17-$.null",
            "json_path": "$.null",
            "lexer_tokens": "DOLLAR, DOT, KEYWORD:null, EOF",
            "source_file_name": "table_17",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$.a",
            "json_path": "$.a",
            "lexer_tokens": "DOLLAR, DOT, ID:a, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$[1]",
            "json_path": "$[1]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:1, RBRACKET, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$[-3]",
            "json_path": "$[-3]",
            "lexer_tokens": "DOLLAR, LBRACKET, INT:-3, RBRACKET, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$.a.b[1:2]",
            "json_path": "$.a.b[1:2]",
            "lexer_tokens": "DOLLAR, DOT, ID:a, DOT, ID:b, LBRACKET, SLICE[1:2], RBRACKET, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$[\"\\u000B\"]",
            "json_path": "$[\"\\u000B\"]",
            "lexer_tokens": "DOLLAR, LBRACKET, STRING:\"\\u000B\", RBRACKET, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        },
        {
            "test_name": "table_18-$[\"\\u0061\"]",
            "json_path": "$[\"\\u0061\"]",
            "lexer_tokens": "DOLLAR, LBRACKET, STRING:\"\\u0061\", RBRACKET, EOF",
            "source_file_name": "table_18",
            "is_invalid": false
        }
    ]
}